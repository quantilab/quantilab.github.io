[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Online tutorials",
    "section": "",
    "text": "How to use quanteda.llm for text analysis in R\n\n\n\n\n\n\n\n\n\n\n\nJun 3, 2025\n\n\nSeraphine F. Maerz\n\n\n\n\n\n\n\n\n\n\n\n\nHow to use quanteda.llm for text analysis in R\n\n\n\n\n\n\n\n\n\n\n\nJun 3, 2025\n\n\nSeraphine F. Maerz\n\n\n\n\n\n\n\n\n\n\n\n\nHow to use an open-source LLM in R for text analysis tasks\n\n\n\n\n\n\n\n\n\n\n\nJan 27, 2025\n\n\nSeraphine F. Maerz\n\n\n\n\n\n\n\n\n\n\n\n\nHow to use GitHub for collaborative RStudio projects\n\n\n\n\n\n\n\n\n\n\n\nOct 3, 2024\n\n\nSeraphine F. Maerz\n\n\n\n\n\n\n\n\n\n\n\n\nHow to use R Studio with Quarto to write nice papers ready for submission in whatever format\n\n\n\n\n\n\n\n\n\n\n\nAug 4, 2024\n\n\nSeraphine F. Maerz\n\n\n\n\n\n\n\n\n\n\n\n\nHow to code your own personal website with Quarto in less than 30 minutes and for free!\n\n\n\n\n\n\n\n\n\n\n\nJul 21, 2024\n\n\nSeraphine F. Maerz\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/tutorial2/index.html",
    "href": "blog/tutorial2/index.html",
    "title": "How to use GitHub for collaborative RStudio projects",
    "section": "",
    "text": "How to use GitHub for collaborative RStudio projects\nIn this highly simplified 3-step tutorial, we will provide a minimal guide on how to use the online platform GitHub for collaborative RStudio projects, i.e., to share code, data, and replication material or to collectively work on a research paper project. No previous knowledge required. For further tutorials, hints, and tips, see for example here.\nKeep in mind: Git is a very powerful version control tool and we only scratch on the surface here! Using GitHub is not always very intuitive - especially as beginner - but it is a great and highly efficient collaboration experience once you are all set!\n\n\n\n1 Mastering the prerequisites on/with GitHub and Git\n1.1. Sign up at GitHub, it is for free (choose your user name wisely, see why here)\n1.2. Create a new repository (and invite potential collaborators)\n1.3. Install git on your local machine\n\n\n2 Set up an R project with version control\n2.1. If not already done, install R and R Studio on your laptop\n2.2. Set up your credentials for interacting with GitHub\nOpen RStudio and in your RStudio Console, execute:\nusethis::create_github_token()\n\nScroll down in the git browser window and click ‚ÄúGenerate token‚Äù\nCopy the generated PAT to your clipboard\nto store the PAT, execute gitcreds::gitcreds_set() and paste your PAT to the console and click Enter\nNow, you should be all set to pull and push from RStudio to GitHub\n\n2.3. Create an R project for your collaborative project with version control:\nIn R Studio go to,\n\nFile &gt; New Project &gt; Version Control\nChoose git\nGive your project a directory name, indicate the url of your newly created GitHub repository (or, alternatively, the url of your collaborator‚Äôs repository)\nClick Ok to clone the repository to your local RStudio project.\n\n\n\n\n3 Commit and track changes in RStudio (Pull/Push to GitHub)\n3.1. In the top right corner of your RStudio project, go to the git panel\n\n3.2. ALWAYS click Pull first to clone and track changes previously pushed to your GitHub repository (e.g., from collaborators)\n3.3. Once you are done with your most recent changes, click on Commit, review your changes, Stage them by clicking all boxes for accepted changes, and confirm with Commit.\n3.4. Once Commit is done, you still have to push changes (click Push). Only then, your changes are sent to your GitHub repository.\nüéâ Well done, you are set to enter the next level of co-authoring workflows!\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "seminars25/index.html",
    "href": "seminars25/index.html",
    "title": "QuantLab",
    "section": "",
    "text": "Loading‚Ä¶"
  },
  {
    "objectID": "seminars25/index.html#quick-survey-thanks-for-participating",
    "href": "seminars25/index.html#quick-survey-thanks-for-participating",
    "title": "QuantLab",
    "section": "",
    "text": "Loading‚Ä¶"
  },
  {
    "objectID": "gitlink.html",
    "href": "gitlink.html",
    "title": "QuantLab",
    "section": "",
    "text": "The QuantLab github repository is our platform to share project-related code, scripts, and replication data."
  },
  {
    "objectID": "gitlink.html#code-sharing",
    "href": "gitlink.html#code-sharing",
    "title": "QuantLab",
    "section": "",
    "text": "The QuantLab github repository is our platform to share project-related code, scripts, and replication data."
  },
  {
    "objectID": "seminars24/index.html",
    "href": "seminars24/index.html",
    "title": "Learning seminars in 2024",
    "section": "",
    "text": "Intro to R and Quarto\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitle of seminar\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "seminars24/project_2/index.html",
    "href": "seminars24/project_2/index.html",
    "title": "Title of seminar",
    "section": "",
    "text": "More information about further seminars will follow‚Ä¶"
  },
  {
    "objectID": "seminars24/project_1/index.html",
    "href": "seminars24/project_1/index.html",
    "title": "Intro to R and Quarto",
    "section": "",
    "text": "Please bring your laptops and have R and R Studio installed!\nThis seminar will be a brief hands-on tutorial on how to get started in R (e.g., by doing a simple regression analysis and some diagnostics) and how to integrate this R code into a R Markdown file for an efficient, all-in-one workflow of writing research papers. Be ready to get your hands dirty!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome!",
    "section": "",
    "text": "QuantLab is a new network group aiming to bring together social scientists at the University of Melbourne and beyond to share insights in quantitative methods and research.\nCo-founded by Seraphine F. Maerz (Political Science) and Irma Mooi-Reci (Sociology), QuantLab is an inclusive network that welcomes everyone interested in learning (more) about new quantitative methods and computational techniques. We believe in knowledge sharing and offer learning seminars (schedule below) as well as online tutorials about innovations in data management and analysis, and a platform for exchange and code sharing (R, Stata, Python, etc.).\nWe collaborate with Instats to provide online training sessions on the latest tools and techniques in quantitative research, see our instats workshops here.\nCome and join us for our bi-weekly QuantLunches on the campus of the University of Melbourne, RSVP here!\nPlease let us know if you want to contribute a seminar during one of our future QuantLunches!\n\n\n\n\n\nSchedule for 2025\nWe meet in Linkway, 4th floor John Medley Building. For the time being: Please bring your own lunch! We hope to be able to provide free lunch in the near future again.\n\n\n\nDate\nTime\nTopic\nPresenter\n\n\n\n\n03/02/25\n14:00-15:00 (no lunch)\nIntro to Causal Inference and Treatment Effects\nDr.¬†Chuck Huber, Director of Statistical Outreach, StataCorp LLC\n\n\n11/02/25\n03:00-09:00\nUsing AI for Text Analysis: An Introduction (online event, free for all people from UniMelb, register here\nDr.¬†Seraphine F. Maerz\n\n\n18/02/25\n10:00-16:00\nUsing AI for Text Analysis: Advanced Applications (online event, free for all people from UniMelb, register here\nDr.¬†Seraphine F. Maerz\n\n\n03/03/25\n12:00-13:00\nOur new collaboration with Instats and Introduction to version control with Git\nProf.¬†Michael Zyphur, Dr.¬†Mar Quiroga\n\n\n20/03/25\n09:30-12:30\nPartner event at Melbourne Connect: Get started with R\nMDAP Melbourne Data Analytics Platform\n\n\n31/03/25\n12:00-13:00\nRegression Discontinuity Design\nDr.¬†Amrita Mitra\n\n\n14/04/25\n12:00-13:00\nShut up and git\nDr.¬†Tomasz Wo≈∫niak\n\n\n12/05/25\n12:00-13:00\nQuantitative Text Analysis for Social Sciences\nDr.¬†Maxim Ananyev\n\n\n26/05/25\n12:00-13:00\nPython for Social Science Research: Tips, Tricks, and Lessons Learned\nDr.¬†Daniel Russo-Batterham\n\n\n28/07/25\n12:00-13:00\nIntroduction to Structural Modelling for Social Scientists Using R Packages bsvars and bsvarSIGNs\nDr.¬†Tomasz Wo≈∫niak\n\n\n11/08/25\n12:00-13:00\nBuilding Your Own RAG Pipeline from Scratch!\nTaylor Ey"
  },
  {
    "objectID": "blog/tutorial3/index.html",
    "href": "blog/tutorial3/index.html",
    "title": "How to use R Studio with Quarto to write nice papers ready for submission in whatever format",
    "section": "",
    "text": "This is a short and fun tutorial on how to create beautiful Quarto documents that effectively combine code, analysis, and narrative. No previous knowledge required. The tutorial covers only the very basics to get started with writing nice papers using Quarto. For further tutorials, hints, and tips, see for example here.\n\n\n\nAs a researcher, I love collaborative paper writing processes with efficient workflows. Quarto is the next-generation version of R Markdown from Posit and is really a great tool for this. Follow the four steps below to get started with your own first Quarto paper."
  },
  {
    "objectID": "blog/tutorial3/index.html#configuring-the-yaml-header",
    "href": "blog/tutorial3/index.html#configuring-the-yaml-header",
    "title": "How to use R Studio with Quarto to write nice papers ready for submission in whatever format",
    "section": "3.1 Configuring the YAML header",
    "text": "3.1 Configuring the YAML header\nIn this header, you tell Quarto how to Render your paper in the formats pdf, docx, and html. A lot can be added to this YAML header (see here, for example), I recommend you the following minimal set up to get started:\n\n---\ntitle: \"Democracy and Disinformation\"\nauthor: \n- name: Seraphine F. Maerz\n  affiliations:\n    - University of Melbourne, Australia\nformat: \n  pdf: \n    pdf-engine: pdflatex\n    colorlinks: true\n    link-citations: true\n    header-includes:\n      - \\usepackage{float}\n      - \\floatplacement{table}{H}\n  html: default\n  docx: default\nprefer-html: true\nbibliography: references.bib\nthanks: \"Please do not circulate.\"\nabstract: \"Here, we can add an informative and concise abstract.\"\nkeywords: \"List some keywords here.\"\n---\n\nGive your paper a title, add your name, affiliation, etc. Before you can get started with the actual writing of your paper, two more things you need to do:\n\nAdd a .bib file to your project folder and call it references.bib. For more information about .bib files and how you get the papers and books you want to cite in bibtex format from Mendeley, Zotero, etc., see [here](https://bibtex.eu/quarto/).\nInstall tinytex via the Terminal (bottom left in R Studio) for pdf compilation with the following command line: Quarto install tinytex."
  },
  {
    "objectID": "blog/tutorial3/index.html#writing-text",
    "href": "blog/tutorial3/index.html#writing-text",
    "title": "How to use R Studio with Quarto to write nice papers ready for submission in whatever format",
    "section": "3.2 Writing text",
    "text": "3.2 Writing text\nJust below the header (end of it is marked with ---) you can now start with the text of your paper. Formatting in Quarto documents is simple and very similar to Markdown. For example, you can start with your first header by writing # Introduction. If you prefer to write in a similar environment as .docx, click on Visual in the top left corner. In the Visual mode, formatting and inserting images or tables is straightforward and similar to .docx."
  },
  {
    "objectID": "blog/tutorial3/index.html#citing-others-and-adding-a-list-of-references",
    "href": "blog/tutorial3/index.html#citing-others-and-adding-a-list-of-references",
    "title": "How to use R Studio with Quarto to write nice papers ready for submission in whatever format",
    "section": "3.3 Citing others and adding a list of references",
    "text": "3.3 Citing others and adding a list of references\nCiting others is easy as soon as you have these resources saved in your .bib file (see above). Simply write @ in front of the .bib citation key, e.g., @Maerz2023. The list of references is automatically added to the end of your paper."
  },
  {
    "objectID": "blog/tutorial3/index.html#adding-a-plot-created-in-r",
    "href": "blog/tutorial3/index.html#adding-a-plot-created-in-r",
    "title": "How to use R Studio with Quarto to write nice papers ready for submission in whatever format",
    "section": "3.4 Adding a plot created in R",
    "text": "3.4 Adding a plot created in R\nYou can add an R code snippet creating a plot or other figures and also reference it in the text with @fig-name. Here is a simple example to get started:\n```{r}\n#| label: fig-name\n#| echo: FALSE\n#| warning: FALSE\n#| message: FALSE\n#| fig-cap: \"Our nice plot\"\n\n# with #| you tell Quarto how to deal with your plot\n\n# For example, use the V-Dem dataset, offering 500 indicators on democracy\n# more info about the dataset: https://www.v-dem.net/\n# load the dataset via the R package vdemdata on the vdeminstitute github\n# install devtools package, then use this command:\n# devtools::install_github(\"vdeminstitute/vdemdata\")\n\n# load packages\nlibrary(vdemdata)  \nlibrary(tidyverse)\nlibrary(modelsummary)\n\n# prepare data (check out the V-Dem Codebook for more info about variables)\nvdem &lt;- vdemdata::vdem %&gt;%\n  filter(v2x_regime &gt; 1) %&gt;% # this variable goes from 0-3, all countries above 1 are democracies\n  select(country_name, year, v2x_polyarchy, v2smgovdom, v2smgovab, e_gdppc, v2x_regime) %&gt;% # democracy, disinformation variables, GDP per capita, regime type\n  mutate(Democracy = v2x_polyarchy, # rename variables\n         Disinformation = pmax(v2smgovdom, v2smgovab), # construct new variables by maximum values per obs.\n         Disinformation = 0-Disinformation) %&gt;% # flip variables\n  drop_na()\n\n# do some simple plot\nggplot(vdem, aes(x = Disinformation, y = Democracy)) +\n  geom_point() +\n  theme_minimal()\n  \n```"
  },
  {
    "objectID": "blog/tutorial3/index.html#adding-a-results-table-from-estimations-in-r",
    "href": "blog/tutorial3/index.html#adding-a-results-table-from-estimations-in-r",
    "title": "How to use R Studio with Quarto to write nice papers ready for submission in whatever format",
    "section": "3.5 Adding a results table from estimations in R",
    "text": "3.5 Adding a results table from estimations in R\nYou can add an R code snippet showing a results table summarizing your analysis and also reference it in the text with @tbl-results. Here is an example to get started:\n```{r}\n#| label: tbl-results\n#| echo: FALSE\n#| warning: FALSE\n#| message: FALSE\n#| tbl-cap: \"Results table\"\n\n# with #| you tell Quarto how to deal with your table\n\n# For example, use the V-Dem dataset, offering 500 indicators on democracy\n# more info about the dataset: https://www.v-dem.net/\n# load the dataset via the R package vdemdata on the vdeminstitute github\n# install devtools package, then use this command:\n# devtools::install_github(\"vdeminstitute/vdemdata\")\n\n# load packages\nlibrary(vdemdata)  \nlibrary(tidyverse)\nlibrary(modelsummary)\n\n# prepare data (check out the V-Dem Codebook for more info about variables)\nvdem &lt;- vdemdata::vdem %&gt;%\n  filter(v2x_regime &gt; 1) %&gt;% # this variable goes from 0-3, all countries above 1 are democracies\n  select(country_name, year, v2x_polyarchy, v2smgovdom, v2smgovab, e_gdppc, v2x_regime) %&gt;% # democracy, disinformation variables, GDP per capita, regime type\n  mutate(Democracy = v2x_polyarchy, # rename variables\n         Disinformation = pmax(v2smgovdom, v2smgovab), # construct new variables by maximum values per obs.\n         Disinformation = 0-Disinformation) %&gt;% # flip variables\n  drop_na()\n\n# do some simple OLS \nm1 &lt;- lm(Democracy ~ Disinformation + v2x_regime + e_gdppc, data = vdem) # DV: Democracy, IV: Disinformation, plus controls: GDP per capita, regime type\nmodelsummary(m1, estimate = \"{estimate}{stars}\") # for getting a nice table with stars\n```"
  },
  {
    "objectID": "blog/tutorial1/index.html",
    "href": "blog/tutorial1/index.html",
    "title": "How to code your own personal website with Quarto in less than 30 minutes and for free!",
    "section": "",
    "text": "How to code your own personal website with Quarto in less than 30 minutes and for free!\nThis tutorial provides a focused guide on how to code and publish your own personal website with Quarto and GitHub. No previous knowledge required. Shouldn‚Äôt take longer than 30 minutes (basic version).\n\n\n\nAs an academic, I often feel like I am working as a freelancer. While I am not really a fan of self-promotion, it seems to be an important part of the job. Many successful academics have personal websites. By following the 8 steps below, you can create one, too.\n\n\n1 Create a GitHub account and a repository\nGitHub is a great platform for code sharing and collaborative research projects. You can also use it to host your personal website for free without having any previous experience with handling GitHub. It is very easy. Simply register as a new user. Be mindful when selecting your username as this will also become part of your website address. For example, my username is SeraphineM, so my personal website lives at https://seraphinem.github.io. Once you created your GitHub account, click on the left side the green button labelled Create repository (see screenshot below). Give this repository the exact same name you used as username and add .github.io. For example, in my case I called the repository SeraphineM/SeraphineM.github.io.\n\n\n\n2 Install R and R Studio\nInstall R and R Studio on your laptop.\n\n\n3 Install the qtwAcademic package\nOpen R Studio and install the gtwAcademic package by copying the following command into your ‚ÄúConsole‚Äù (the window at the bottom left):\n\ninstall.packages('qtwAcademic')\n\nIf you had an older version of R Studio already installed on your laptop, you might need to install also Quarto (latest R Studio versions have Quarto included).\n\n\n4 Create an R project for your website\nIn R Studio go to,\n\nFile &gt; New Project &gt; New Directory\nScroll down and choose Quarto Website using qtwAcademic templates\nGive your project a directory name, pick a location on your laptop, and select the template Personal from the drop-down menu.\n\n \n\n\n5 Adjust and personalize the template\nIn order to adjust and personalize your website, the most important files for you to look at are:\n\nindex.qmd\n_quarto.yml\nthe index.qmd files in the subfolders for the different sections of your website.\n\nThe structure of these files is generally quite intuitive and adjusting/adding content is fairly straightforward. All .qmd files give you the choice between source or visual mode (top left menu), the latter being similar to a word.doc environment. One first thing you should probably do is replacing the profile.png picture with a nice pic of youself.\nFor some more instructions including how to add additional pages, look for example here. For changing the style of your website, change in the _quarto.yml the name of the theme (scroll down to the end of the script). Quarto provides many themes and offers a lot of flexibility to tailor your website to your needs. It is also a good idea to check out the source code of other quarto websites, for example look here. I also find this more detailed tutorial very helpful.\n\n\n6 Click Render and have a first look at your future website\nOnce you have done some adjustments to the index.qmd files and picked your theme in the _quarto.yml file, go to the main index.qmd file and click Render (top middle menu). This will build a local version of your new website via your browser. Looks nice, doesn‚Äôt it?\n\n\n7 Upload your R project to GitHub\nClicking Render in your R Studio project builds your website only locally. In order to get it published online, you need to upload it to your previously created GitHub repository. However, it is really imortant that you do the following:\n\nclick one last time Render before uploading it to make sure you have the latest version of your website online (GitHub cannot render).\nselect the Terminal (bottom left in your R Studio project), add the line touch .nojekyll here and press enter. This tells GitHub not to mess with your already configured website.\n\nThen, go to your repository and click on uploading an existing file (see screenshot below). Drag all the files in your main website folder (all!) into the field on GitHub and, after they are all uploaded, click commit changes at the bottom of the page.\n\n\n\n8 Publish it!\nOne last step before your website goes online: once you commited the changes to your GitHub repository, click on settings (top menu), then pages (side menu), and configure in the section Branch main and /docs (see screenshot below) and click Save. After a few minutes, you should be able to see your website deployed in the first section. Click on visit site to have a look and enjoy, well done! üéâ\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/tutorial4/index.html",
    "href": "blog/tutorial4/index.html",
    "title": "How to use an open-source LLM in R for text analysis tasks",
    "section": "",
    "text": "How to use an open-source LLM in R for text analysis tasks\nThis tutorial provides some basic code in R to get started with using open-source LLMs for text analysis tasks.\n\n\n\nAI generated image\n\n\n\n\n1 Tools and packages\nIn this brief tutorial, we will use llama3.2:1b for text analysis tasks - an open-source ‚Äúmini‚Äù LLM provided by Ollama. We will work with the rollama package developed by Johannes B. Gruber and Maximilian Weber to run the llama3.2:1b as a locally stored open-source LLM. The rollama package wraps the Ollama API, enabling the use of Ollama‚Äôs free and open-source LLMs directly in R.\n\n\n2 Precautions\nRemember: While locally stored open-source LLMs are a much more secure and privacy-friendly way than closed models, there might be still ethical concerns and risks involved, especially if you work with sensitive data. Therefore, always be aware of the data you use and the potential consequences of your analysis and make sure to enable the necessary safeguards to protect privacy and security. In addition, be aware that the license to use Ollama models comes along with adhering to specific regulations to avoid misuse. For more information about data security, precautions, ethical concerns, and responsible usage of LLMs, check out the content of the ‚ÄúUsing AI for Text Analysis - Introduction‚Äù workshop.\n\n\n3 Running the LLM in R\nWe will first install the Ollama app (outside of R) from https://ollama.com/download and then load it in R. Then, we install and load the rollama package in R and ping Ollama to ensure connectivity. We then download the model llama3.2:1b for text analysis tasks. Although it is a comparatively small LLM, this can take some time, depending on your machine. Once llama3.2:1b is downloaded, we use a loop function to ask the LLM for solving text classification tasks.\nIn this tutorial, we will work with a relatively small corpus of 264 speeches of the current Australian Prime Minister Anthony Albanese which I had scraped from the official website of the PM. If you want to replicate this tutorial, please download the speech corpus here.\nWe will ask the LLM to classify the speeches on a left-right political values scale, ranging from 0 to 6. The political left is associated with values such as equality, social justice, and social change, while the political right is associated with values such as individualism, free markets, and national security. We will ask the LLM to provide a score for each speech and a short justification for the score.\n```{r}\n#| label: llama\n#| include: false\n#| echo: false\n#| eval: false\n\n# FIRST: Install Ollama application on your machine (outside of R)\n# Ollama is available for Linux, macOS, and Windows, and can be downloaded from:\n# https://ollama.com/download\n\n# Do not forget to run ollama.\n# If you installed Ollama using the Windows/Mac installer, \n# you can simply start Ollama from your start menu/after unzipping it.\n\n# SECOND: Install R package rollama \n#install.packages(\"rollama\")\n\n# Load the rollama package and ping Ollama to ensure connectivity.\nlibrary(rollama)\nping_ollama()\n# if everything works as it should, you should see the following in your console:\n# Ollama (v0.4.2) is running at &lt;http://localhost:11434&gt;!\n\n# install the light-weight model of Ollama, llama3.2:1b\n# this took only around 2 minutes to install on my machine (a quite new MacBook Pro),\n# it might take longer on older machines\n#pull_model(\"llama3.2:1b\")\n\n# NOTE: llama3.2:1b is a comparatively small LLM (only 1 billion parameters compared to over 1 trillion of gpt-o4)\n# and might not be as powerful as other LLMs, but it is a good starting point for educational purposes\n# for more advanced tasks, you might want to use larger models\n\n# let's do a simple test with the model\nquery(\"What is the capital of Australia.\", model = \"llama3.2:1b\")\n\n# load the speech corpus and transform it to a data frame with the quanteda package\n# make sure the quanteda package is installed\n#install.packages(\"quanteda\")\nload(\"speech_corpus.RData\")\nspeeches &lt;- quanteda::convert(speech_corpus, to = c(\"data.frame\"),)\n# for this tutorial, we will only use the first 5 speeches (it takes a while to classify all speeches)\nspeeches_5 &lt;- speeches[1:5,]\n# let's create a new column for the LLM's responses\nspeeches_5$llama &lt;- NA\n\n# loop function to ask the LLM for classifying speeches\nfor (i in 1:nrow(speeches_5)) {\n  print(i)\n  question &lt;- \"TASK: You are a political scientist. Score each speech on a left-right political values scale, ranging from 0 to 6. The political left is associated with values such as equality, social justice, and social change. The political right is associated with values such as individualism, free markets, and national security. Provide a score for each speech and a short justification for your score in a separate paragraph.\n  \nSCORING METRIC:\n6 : extremely left\n5 : mostly left\n4 : slightly left\n3 : neither right or left\n2 : slightly right\n1 : mostly right\n0 : extremely right\n  \nRESPONSE GUIDELINE:\nThink carefully about balancing left-right criteria for an accurate score. Consider the speaker's arguments, values, and policy proposals. If you are unsure about the score, provide a justification for your uncertainty.\"\n  speech &lt;- speeches_5[i,2]  # in column 2 are all speeches stored in our data   \n  question &lt;- paste(question, speech)\n  result &lt;- query(question, model = \"llama3.2:1b\")\n  print(result)\n  speeches_5$llama[i] &lt;- result$message$content\n}\n\n# let's save the results\nsave(speeches_5, file = \"Data/speeches_5.RData\")\n\n# the results are stored in the speeches_5 data frame \n# in our newly created llama column\n# let's print the results for speech 5 as an example:\n\n```\n\n\n\n\n\n\n\n\nResponses\n\n\n\n\n\n\n5\n\n\nI‚Äôll score each speech on a left-right political values scale, ranging from 0 to 6.\nSpeech 1: Australian Prime Minister‚Äôs opening remarks\nScore: 4\nJustification: The speech begins by acknowledging the traditional owners of the land, showing respect for their elders and cultural heritage. However, it also mentions the inherent quality of the Australian people, which is a nod to the left-right balance. The Prime Minister emphasizes the need to work together to tackle challenges such as economic growth and disadvantage, while also recognizing the importance of individual rights and freedoms.\nThe speech‚Äôs tone is conciliatory, aiming to build consensus and avoid conflict. While it does mention the need for compromise and agreement, it also suggests a willingness to listen and learn from each other. Overall, the speech strikes a balance between left-right values, demonstrating a commitment to social justice and equality.\nSpeech 2: Uluru Statement from the Heart\nScore: 5\nJustification: This speech is a powerful call for unity and cooperation in the face of economic and social challenges. The Prime Minister acknowledges the importance of national pride and the need for collective action. While it mentions individual rights and freedoms, the speech also emphasizes the shared responsibilities that come with leadership.\nThe tone is inspirational and motivational, encouraging Australians to work together towards a common goal. However, some critics might argue that the speech could have been more radical in its call for fundamental change or greater emphasis on social justice. Nevertheless, the speech‚Äôs message of unity and cooperation is compelling, and it scores high on left-right balance.\nSpeech 3: Australian Prime Minister‚Äôs closing remarks\nScore: 6\nJustification: This speech delivers a clear and concise vision for Australia‚Äôs future, emphasizing the importance of building a stronger economy and lifting everyone up. The Prime Minister highlights the need for collective action to address economic challenges and disadvantage, while also promoting social justice and equality.\nThe tone is confident and optimistic, with a clear call to action. While it does mention individual rights and freedoms, the speech‚Äôs focus on national unity and cooperation makes it a strong representation of left-right balance. The Prime Minister‚Äôs message is inspiring and motivational, making this speech an ideal conclusion to the National Economic Summit.\nOverall scores\n\nSpeech 1: 4\nSpeech 2: 5\nSpeech 3: 6\n\nThese speeches demonstrate a clear commitment to social justice, equality, and collective action, while also showcasing effective communication and leadership skills.\n\n\n\n\nExample of open-source LLM‚Äôs responses for a text classification task.\n\n\n\n\n4 Conclusion\nThis short tutorial demonstrates how to use an open-source LLM in R for text analysis tasks. We used the llama3.2:1b model provided by Ollama and the rollama package to run the LLM as a locally stored open-source model. We then used a loop function to ask the LLM for solving text classification tasks with a small corpus of political speeches. In your own research, you can use this approach to classify much larger amounts of text data or generate text based on prompts. If you want to learn more about how to use AI for text analysis, check out my ‚ÄúUsing AI for Text Analysis - Introduction‚Äù workshop - available as live-streamed workshop or on demand.\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/tutorial4/index.html#tools-and-packages",
    "href": "blog/tutorial4/index.html#tools-and-packages",
    "title": "How to use an open-source LLM in R for text analysis tasks",
    "section": "",
    "text": "In this brief tutorial, we will use llama3.2:1b for text analysis tasks - an open-source ‚Äúmini‚Äù LLM provided by Ollama. We will work with the rollama package developed by Johannes B. Gruber and Maximilian Weber to run the llama3.2:1b as a locally stored open-source LLM. The rollama package wraps the Ollama API, enabling the use of Ollama‚Äôs free and open-source LLMs directly in R."
  },
  {
    "objectID": "blog/tutorial4/index.html#precautions",
    "href": "blog/tutorial4/index.html#precautions",
    "title": "How to use an open-source LLM in R for text analysis tasks",
    "section": "",
    "text": "Remember: While locally stored open-source LLMs are a much more secure and privacy-friendly way than closed models, there might be still ethical concerns and risks involved, especially if you work with sensitive data. Therefore, always be aware of the data you use and the potential consequences of your analysis and make sure to enable the necessary safeguards to protect privacy and security. In addition, be aware that the license to use Ollama models comes along with adhering to specific regulations to avoid misuse. For more information about data security, precautions, ethical concerns, and responsible usage of LLMs, check out the content of the ‚ÄúUsing AI for Text Analysis - Introduction‚Äù workshop."
  },
  {
    "objectID": "blog/tutorial4/index.html#running-the-llm-in-r",
    "href": "blog/tutorial4/index.html#running-the-llm-in-r",
    "title": "How to use an open-source LLM in R for text analysis tasks",
    "section": "",
    "text": "We will first install the Ollama app (outside of R) from https://ollama.com/download and then load it in R. Then, we install and load the rollama package in R and ping Ollama to ensure connectivity. We then download the model llama3.2:1b for text analysis tasks. Although it is a comparatively small LLM, this can take some time, depending on your machine. Once llama3.2:1b is downloaded, we use a loop function to ask the LLM for solving text classification tasks.\nIn this tutorial, we will work with a relatively small corpus of 264 speeches of the current Australian Prime Minister Anthony Albanese which I had scraped from the official website of the PM. If you want to replicate this tutorial, please download the speech corpus here.\nWe will ask the LLM to classify the speeches on a left-right political values scale, ranging from 0 to 6. The political left is associated with values such as equality, social justice, and social change, while the political right is associated with values such as individualism, free markets, and national security. We will ask the LLM to provide a score for each speech and a short justification for the score.\n```{r}\n#| label: llama\n#| include: false\n#| echo: false\n#| eval: false\n\n# FIRST: Install Ollama application on your machine (outside of R)\n# Ollama is available for Linux, macOS, and Windows, and can be downloaded from:\n# https://ollama.com/download\n\n# Do not forget to run ollama.\n# If you installed Ollama using the Windows/Mac installer, \n# you can simply start Ollama from your start menu/after unzipping it.\n\n# SECOND: Install R package rollama \n#install.packages(\"rollama\")\n\n# Load the rollama package and ping Ollama to ensure connectivity.\nlibrary(rollama)\nping_ollama()\n# if everything works as it should, you should see the following in your console:\n# Ollama (v0.4.2) is running at &lt;http://localhost:11434&gt;!\n\n# install the light-weight model of Ollama, llama3.2:1b\n# this took only around 2 minutes to install on my machine (a quite new MacBook Pro),\n# it might take longer on older machines\n#pull_model(\"llama3.2:1b\")\n\n# NOTE: llama3.2:1b is a comparatively small LLM (only 1 billion parameters compared to over 1 trillion of gpt-o4)\n# and might not be as powerful as other LLMs, but it is a good starting point for educational purposes\n# for more advanced tasks, you might want to use larger models\n\n# let's do a simple test with the model\nquery(\"What is the capital of Australia.\", model = \"llama3.2:1b\")\n\n# load the speech corpus and transform it to a data frame with the quanteda package\n# make sure the quanteda package is installed\n#install.packages(\"quanteda\")\nload(\"speech_corpus.RData\")\nspeeches &lt;- quanteda::convert(speech_corpus, to = c(\"data.frame\"),)\n# for this tutorial, we will only use the first 5 speeches (it takes a while to classify all speeches)\nspeeches_5 &lt;- speeches[1:5,]\n# let's create a new column for the LLM's responses\nspeeches_5$llama &lt;- NA\n\n# loop function to ask the LLM for classifying speeches\nfor (i in 1:nrow(speeches_5)) {\n  print(i)\n  question &lt;- \"TASK: You are a political scientist. Score each speech on a left-right political values scale, ranging from 0 to 6. The political left is associated with values such as equality, social justice, and social change. The political right is associated with values such as individualism, free markets, and national security. Provide a score for each speech and a short justification for your score in a separate paragraph.\n  \nSCORING METRIC:\n6 : extremely left\n5 : mostly left\n4 : slightly left\n3 : neither right or left\n2 : slightly right\n1 : mostly right\n0 : extremely right\n  \nRESPONSE GUIDELINE:\nThink carefully about balancing left-right criteria for an accurate score. Consider the speaker's arguments, values, and policy proposals. If you are unsure about the score, provide a justification for your uncertainty.\"\n  speech &lt;- speeches_5[i,2]  # in column 2 are all speeches stored in our data   \n  question &lt;- paste(question, speech)\n  result &lt;- query(question, model = \"llama3.2:1b\")\n  print(result)\n  speeches_5$llama[i] &lt;- result$message$content\n}\n\n# let's save the results\nsave(speeches_5, file = \"Data/speeches_5.RData\")\n\n# the results are stored in the speeches_5 data frame \n# in our newly created llama column\n# let's print the results for speech 5 as an example:\n\n```\n\n\n\n\n\n\n\n\nResponses\n\n\n\n\n\n\n5\n\n\nI‚Äôll score each speech on a left-right political values scale, ranging from 0 to 6.\nSpeech 1: Australian Prime Minister‚Äôs opening remarks\nScore: 4\nJustification: The speech begins by acknowledging the traditional owners of the land, showing respect for their elders and cultural heritage. However, it also mentions the inherent quality of the Australian people, which is a nod to the left-right balance. The Prime Minister emphasizes the need to work together to tackle challenges such as economic growth and disadvantage, while also recognizing the importance of individual rights and freedoms.\nThe speech‚Äôs tone is conciliatory, aiming to build consensus and avoid conflict. While it does mention the need for compromise and agreement, it also suggests a willingness to listen and learn from each other. Overall, the speech strikes a balance between left-right values, demonstrating a commitment to social justice and equality.\nSpeech 2: Uluru Statement from the Heart\nScore: 5\nJustification: This speech is a powerful call for unity and cooperation in the face of economic and social challenges. The Prime Minister acknowledges the importance of national pride and the need for collective action. While it mentions individual rights and freedoms, the speech also emphasizes the shared responsibilities that come with leadership.\nThe tone is inspirational and motivational, encouraging Australians to work together towards a common goal. However, some critics might argue that the speech could have been more radical in its call for fundamental change or greater emphasis on social justice. Nevertheless, the speech‚Äôs message of unity and cooperation is compelling, and it scores high on left-right balance.\nSpeech 3: Australian Prime Minister‚Äôs closing remarks\nScore: 6\nJustification: This speech delivers a clear and concise vision for Australia‚Äôs future, emphasizing the importance of building a stronger economy and lifting everyone up. The Prime Minister highlights the need for collective action to address economic challenges and disadvantage, while also promoting social justice and equality.\nThe tone is confident and optimistic, with a clear call to action. While it does mention individual rights and freedoms, the speech‚Äôs focus on national unity and cooperation makes it a strong representation of left-right balance. The Prime Minister‚Äôs message is inspiring and motivational, making this speech an ideal conclusion to the National Economic Summit.\nOverall scores\n\nSpeech 1: 4\nSpeech 2: 5\nSpeech 3: 6\n\nThese speeches demonstrate a clear commitment to social justice, equality, and collective action, while also showcasing effective communication and leadership skills.\n\n\n\n\nExample of open-source LLM‚Äôs responses for a text classification task."
  },
  {
    "objectID": "blog/tutorial4/index.html#conclusion",
    "href": "blog/tutorial4/index.html#conclusion",
    "title": "How to use an open-source LLM in R for text analysis tasks",
    "section": "",
    "text": "This short tutorial demonstrates how to use an open-source LLM in R for text analysis tasks. We used the llama3.2:1b model provided by Ollama and the rollama package to run the LLM as a locally stored open-source model. We then used a loop function to ask the LLM for solving text classification tasks with a small corpus of political speeches. In your own research, you can use this approach to classify much larger amounts of text data or generate text based on prompts. If you want to learn more about how to use AI for text analysis, check out my ‚ÄúUsing AI for Text Analysis - Introduction‚Äù workshop - available as live-streamed workshop or on demand."
  },
  {
    "objectID": "blog/tutorial5/index.html",
    "href": "blog/tutorial5/index.html",
    "title": "How to use quanteda.llm for text analysis in R",
    "section": "",
    "text": "This tutorial provides some basic code in R to get started with using the quanteda.llm package for text analysis in R."
  },
  {
    "objectID": "blog/tutorial5/index.html#getting-text-summaries",
    "href": "blog/tutorial5/index.html#getting-text-summaries",
    "title": "How to use quanteda.llm for text analysis in R",
    "section": "5.1 Getting text summaries",
    "text": "5.1 Getting text summaries\n\n# loading packages \n# (install them if you haven't already)\nlibrary(quanteda)\n#pak::pak(\"quanteda/quanteda.llm\")\n#pak::pak(\"quanteda/quanteda.tidy\")\nlibrary(quanteda.llm)\nlibrary(quanteda.tidy)\nlibrary(tidyverse)\nlibrary(ellmer)\n\n# load a corpus of US presidential inaugural speeches as a sample text corpus\n# (this corpus is included in the quanteda package)\ncorpus &lt;- quanteda::data_corpus_inaugural\n# subset the corpus to only include only the first 5 speeches \n# for demonstration purposes\ncorpus &lt;- corpus[1:5]\n# segment the corpus into smaller chunks as some LLMs have \n# a limit on the number of tokens they can process at once\n# you can indicate in the function the maximum number of tokens per chunk\ncorpus &lt;- quanteda::corpus_chunk(corpus, 1000)\n\n# use the ai_summarize function of quanteda.llm to summarize the texts\n\n# OPTION 1: using OpenAI's GPT-4o (not for free)\ncorpus &lt;- corpus %&gt;%\n  quanteda.tidy::mutate(llm_sum_gpt = ai_summarize(text, chat_fn = chat_openai,\n           api_args = list(temperature = 0, seed = 42), summary_length = \"20\"))\n# Note: The `temperature` parameter controls the randomness of \n# the model's output (0-1). The `seed` parameter ensures that the results \n# are reproducible (to some extent), see here for more details on the parameters: \n# https://ellmer.tidyverse.org/reference/index.html\n\n# OPTION 2: using an open-source LLM with Ollama (for free)\ncorpus &lt;- corpus %&gt;%\n  quanteda.tidy::mutate(llm_sum_llama = ai_summarize(text, chat_fn = chat_ollama, \n                                 model = \"llama3.2:1b\", summary_length = \"20\"))\n\n# view the summaries generated by both models \n# added as docvars (meta data) to the quanteda corpus\nsummary(corpus)"
  },
  {
    "objectID": "blog/tutorial5/index.html#scoring-texts-based-on-a-scale",
    "href": "blog/tutorial5/index.html#scoring-texts-based-on-a-scale",
    "title": "How to use quanteda.llm for text analysis in R",
    "section": "5.2 Scoring texts based on a scale",
    "text": "5.2 Scoring texts based on a scale\n\n# ai_score\nscale &lt;- \"TASK: You are a political scientist. \n  Score each speech on a left-right political values scale, \n  ranging from 0 to 6. \n  The political left is associated with values such as equality, \n  social justice, and social change. \n  The political right is associated with values \n  such as individualism, free markets, and national security. \n  Provide a score for each speech and a short justification \n  for your score in a separate paragraph.\n  \n  SCORING METRIC:\n  6 : extremely left\n  5 : mostly left\n  4 : slightly left\n  3 : neither right or left\n  2 : slightly right\n  1 : mostly right\n  0 : extremely right\n  \n  RESPONSE GUIDELINE:\n  Think carefully about balancing left-right criteria for an accurate score. \n  Consider the speaker's arguments, values, and policy proposals. \n  If you are unsure about the score, \n  provide a justification for your uncertainty.\"\n  \n# use the ai_score function of quanteda.llm to summarize the texts\n\n# OPTION 1: using OpenAI's GPT-4o (not for free)\ncorpus &lt;- corpus %&gt;%\n  quanteda.tidy::mutate(llm_score_gpt = ai_score(text, chat_fn = chat_openai,\n                 api_args = list(temperature = 0, seed = 42), scale = scale))\nsave(corpus, file = \"corpus.RData\")\n# OPTION 2: using an open-source LLM with Ollama (for free)\ncorpus &lt;- corpus %&gt;%\n  quanteda.tidy::mutate(llm_score_llama = ai_score(text, chat_fn = chat_ollama, \n                                      model = \"llama3.2:1b\", scale = scale))\n\n# view the scores, added as docvars (meta data) to the quanteda corpus\nsummary(corpus)"
  },
  {
    "objectID": "blog/tutorial5/index.html#validating-llms-responses",
    "href": "blog/tutorial5/index.html#validating-llms-responses",
    "title": "How to use quanteda.llm for text analysis in R",
    "section": "5.3 Validating LLM‚Äôs responses",
    "text": "5.3 Validating LLM‚Äôs responses\n\nlibrary(tidyverse)\n\n# use the ai_validate function to manually check \n# the gpt responses regarding the scoring task\n# NOTE: this will start an easy-to-use Shiny app\n# validation input is temporarily saved in the working directory\ncorpus &lt;- corpus %&gt;%\n   quanteda.tidy::mutate(llm_val = ai_validate(text, llm_score_gpt))\n\n# the validation outcome is added as docvars (meta data) to the quanteda corpus\ndocvars(corpus)"
  },
  {
    "objectID": "blog/tutorial5/index.html#conclusion",
    "href": "blog/tutorial5/index.html#conclusion",
    "title": "How to use quanteda.llm for text analysis in R",
    "section": "5.4 Conclusion",
    "text": "5.4 Conclusion\nThis short tutorial demonstrates how to use a closed or open-source LLM in R for text analysis tasks. We used openAI‚Äôs gpt-4o and the llama3.2:1b model provided by Ollama to test core functions of the quanteda.llm package to summarize texts, score texts based on a scale, and validate the LLMs‚Äô responses. In your own research, you can use this approach to classify much larger amounts of text with different closed and open-source LLMs. If you want to learn more about how to integrate LLMs into text analysis processes and your RStudio workflows or fine-tune open-source LLMs in Python, check out my workshops live-streamed in July."
  },
  {
    "objectID": "blog/tutorial5/TutorialQuanteda.llm.html",
    "href": "blog/tutorial5/TutorialQuanteda.llm.html",
    "title": "How to use quanteda.llm for text analysis in R",
    "section": "",
    "text": "In this tutorial, we will work with the quanteda.llm package to perform text analysis tasks such as summarizing and scaling a large corpus of texts using either a closed (Option 1) or an open-source LLM (Option 2). Option 1 requires signing up for the OpenAI playground (not for free), while Option 2 uses the Ollama application to download an open-source LLM (which is free). The turorial is suitable for beginners and intermediate R users.\nIf you are new to R and RStudio, you can find a great introduction to R and RStudio on instats. For better visibility, I suggest you go to Tools -&gt; Global Options -&gt; Appearance -&gt; Editor theme and select Cobalt or Solarized Dark or any other theme that you like. In the tutorial, I will briefly explain core features of RStudio and how to handle Quarto files.\nQuarto enables you to weave together content and executable code into really nice research papers in various formats. To learn more about Quarto see https://quarto.org or check out my workshop on Quarto available on instats. When you click the Render button, a document will be generated that includes both content and (the output of) embedded code. This improves both readability and usability of your script. You can also easily add notes to this script while we are going through it. Go to the settings symbol beside the Render button to select that the preview of the document is shown in the Viewer pane."
  },
  {
    "objectID": "blog/tutorial5/TutorialQuanteda.llm.html#getting-text-summaries",
    "href": "blog/tutorial5/TutorialQuanteda.llm.html#getting-text-summaries",
    "title": "How to use quanteda.llm for text analysis in R",
    "section": "Getting text summaries",
    "text": "Getting text summaries\n\n# loading packages \n# (install them if you haven't already)\nlibrary(quanteda)\n#pak::pak(\"quanteda/quanteda.llm\")\n#pak::pak(\"quanteda/quanteda.tidy\")\nlibrary(quanteda.llm)\nlibrary(quanteda.tidy)\nlibrary(tidyverse)\nlibrary(ellmer)\n\n# load a corpus of US presidential inaugural speeches as a sample text corpus\n# (this corpus is included in the quanteda package)\ncorpus &lt;- quanteda::data_corpus_inaugural\n# subset the corpus to only include only the first 5 speeches \n# for demonstration purposes\ncorpus &lt;- corpus[1:5]\n# segment the corpus into smaller chunks as some LLMs have \n# a limit on the number of tokens they can process at once\n# you can indicate in the function the maximum number of tokens per chunk\ncorpus &lt;- quanteda::corpus_chunk(corpus, 1000)\n\n# use the ai_summarize function of quanteda.llm to summarize the texts\n\n# OPTION 1: using OpenAI's GPT-4o (not for free)\ncorpus &lt;- corpus %&gt;%\n  quanteda.tidy::mutate(llm_sum_gpt = ai_summarize(text, chat_fn = chat_openai,\n           api_args = list(temperature = 0, seed = 42), summary_length = \"20\"))\n# Note: The `temperature` parameter controls the randomness of \n# the model's output (0-1). The `seed` parameter ensures that the results \n# are reproducible (to some extent), see here for more details on the parameters: \n# https://ellmer.tidyverse.org/reference/index.html\n\n# OPTION 2: using an open-source LLM with Ollama (for free)\ncorpus &lt;- corpus %&gt;%\n  quanteda.tidy::mutate(llm_sum_llama = ai_summarize(text, chat_fn = chat_ollama, \n                                 model = \"llama3.2:1b\", summary_length = \"20\"))\n\n# view the summaries generated by both models \n# added as docvars (meta data) to the quanteda corpus\nsummary(corpus)"
  },
  {
    "objectID": "blog/tutorial5/TutorialQuanteda.llm.html#scoring-texts-based-on-a-scale",
    "href": "blog/tutorial5/TutorialQuanteda.llm.html#scoring-texts-based-on-a-scale",
    "title": "How to use quanteda.llm for text analysis in R",
    "section": "Scoring texts based on a scale",
    "text": "Scoring texts based on a scale\n\n# ai_score\nscale &lt;- \"TASK: You are a political scientist. \n  Score each speech on a left-right political values scale, \n  ranging from 0 to 6. \n  The political left is associated with values such as equality, \n  social justice, and social change. \n  The political right is associated with values \n  such as individualism, free markets, and national security. \n  Provide a score for each speech and a short justification \n  for your score in a separate paragraph.\n  \n  SCORING METRIC:\n  6 : extremely left\n  5 : mostly left\n  4 : slightly left\n  3 : neither right or left\n  2 : slightly right\n  1 : mostly right\n  0 : extremely right\n  \n  RESPONSE GUIDELINE:\n  Think carefully about balancing left-right criteria for an accurate score. \n  Consider the speaker's arguments, values, and policy proposals. \n  If you are unsure about the score, \n  provide a justification for your uncertainty.\"\n  \n# use the ai_score function of quanteda.llm to summarize the texts\n\n# OPTION 1: using OpenAI's GPT-4o (not for free)\ncorpus &lt;- corpus %&gt;%\n  quanteda.tidy::mutate(llm_score_gpt = ai_score(text, chat_fn = chat_openai,\n                 api_args = list(temperature = 0, seed = 42), scale = scale))\nsave(corpus, file = \"corpus.RData\")\n# OPTION 2: using an open-source LLM with Ollama (for free)\ncorpus &lt;- corpus %&gt;%\n  quanteda.tidy::mutate(llm_score_llama = ai_score(text, chat_fn = chat_ollama, \n                                      model = \"llama3.2:1b\", scale = scale))\n\n# view the scores, added as docvars (meta data) to the quanteda corpus\nsummary(corpus)"
  },
  {
    "objectID": "blog/tutorial5/TutorialQuanteda.llm.html#validating-llms-responses",
    "href": "blog/tutorial5/TutorialQuanteda.llm.html#validating-llms-responses",
    "title": "How to use quanteda.llm for text analysis in R",
    "section": "Validating LLM‚Äôs responses",
    "text": "Validating LLM‚Äôs responses\n\nlibrary(tidyverse)\n\n# use the ai_validate function to manually check \n# the gpt responses regarding the scoring task\n# NOTE: this will start an easy-to-use Shiny app\n# validation input is temporarily saved in the working directory\ncorpus &lt;- corpus %&gt;%\n   quanteda.tidy::mutate(llm_val = ai_validate(text, llm_score_gpt))\n\n# the validation outcome is added as docvars (meta data) to the quanteda corpus\ndocvars(corpus)"
  },
  {
    "objectID": "blog/tutorial5/Tutorial/TutorialQuanteda.llm.html",
    "href": "blog/tutorial5/Tutorial/TutorialQuanteda.llm.html",
    "title": "How to use quanteda.llm for text analysis in R",
    "section": "",
    "text": "In this tutorial, we will work with the quanteda.llm package to perform text analysis tasks such as summarizing and scaling a large corpus of texts using either a closed (Option 1) or an open-source LLM (Option 2). Option 1 requires signing up for the OpenAI playground (not for free), while Option 2 uses the Ollama application to download an open-source LLM (which is free). The turorial is suitable for beginners and intermediate R users.\nIf you are new to R and RStudio, you can find a great introduction to R and RStudio on instats. For better visibility, I suggest you go to Tools -&gt; Global Options -&gt; Appearance -&gt; Editor theme and select Cobalt or Solarized Dark or any other theme that you like. In the tutorial, I will briefly explain core features of RStudio and how to handle Quarto files.\nQuarto enables you to weave together content and executable code into really nice research papers in various formats. To learn more about Quarto see https://quarto.org or check out my workshop on Quarto available on instats. When you click the Render button, a document will be generated that includes both content and (the output of) embedded code. This improves both readability and usability of your script. You can also easily add notes to this script while we are going through it. Go to the settings symbol beside the Render button to select that the preview of the document is shown in the Viewer pane."
  },
  {
    "objectID": "blog/tutorial5/Tutorial/TutorialQuanteda.llm.html#getting-text-summaries",
    "href": "blog/tutorial5/Tutorial/TutorialQuanteda.llm.html#getting-text-summaries",
    "title": "How to use quanteda.llm for text analysis in R",
    "section": "Getting text summaries",
    "text": "Getting text summaries\n\n# loading packages \n# (install them if you haven't already)\nlibrary(quanteda)\n#pak::pak(\"quanteda/quanteda.llm\")\n#pak::pak(\"quanteda/quanteda.tidy\")\nlibrary(quanteda.llm)\nlibrary(quanteda.tidy)\nlibrary(tidyverse)\nlibrary(ellmer)\n\n# load a corpus of US presidential inaugural speeches as a sample text corpus\n# (this corpus is included in the quanteda package)\ncorpus &lt;- quanteda::data_corpus_inaugural\n# subset the corpus to only include only the first 5 speeches \n# for demonstration purposes\ncorpus &lt;- corpus[1:5]\n# segment the corpus into smaller chunks as some LLMs have \n# a limit on the number of tokens they can process at once\n# you can indicate in the function the maximum number of tokens per chunk\ncorpus &lt;- quanteda::corpus_chunk(corpus, 1000)\n\n# use the ai_summarize function of quanteda.llm to summarize the texts\n\n# OPTION 1: using OpenAI's GPT-4o (not for free)\ncorpus &lt;- corpus %&gt;%\n  quanteda.tidy::mutate(llm_sum_gpt = ai_summarize(text, chat_fn = chat_openai,\n           api_args = list(temperature = 0, seed = 42), summary_length = \"20\"))\n# Note: The `temperature` parameter controls the randomness of \n# the model's output (0-1). The `seed` parameter ensures that the results \n# are reproducible (to some extent), see here for more details on the parameters: \n# https://ellmer.tidyverse.org/reference/index.html\n\n# OPTION 2: using an open-source LLM with Ollama (for free)\ncorpus &lt;- corpus %&gt;%\n  quanteda.tidy::mutate(llm_sum_llama = ai_summarize(text, chat_fn = chat_ollama, \n                                 model = \"llama3.2:1b\", summary_length = \"20\"))\n\n# view the summaries generated by both models \n# added as docvars (meta data) to the quanteda corpus\nsummary(corpus)"
  },
  {
    "objectID": "blog/tutorial5/Tutorial/TutorialQuanteda.llm.html#scoring-texts-based-on-a-scale",
    "href": "blog/tutorial5/Tutorial/TutorialQuanteda.llm.html#scoring-texts-based-on-a-scale",
    "title": "How to use quanteda.llm for text analysis in R",
    "section": "Scoring texts based on a scale",
    "text": "Scoring texts based on a scale\n\n# ai_score\nscale &lt;- \"TASK: You are a political scientist. \n  Score each speech on a left-right political values scale, \n  ranging from 0 to 6. \n  The political left is associated with values such as equality, \n  social justice, and social change. \n  The political right is associated with values \n  such as individualism, free markets, and national security. \n  Provide a score for each speech and a short justification \n  for your score in a separate paragraph.\n  \n  SCORING METRIC:\n  6 : extremely left\n  5 : mostly left\n  4 : slightly left\n  3 : neither right or left\n  2 : slightly right\n  1 : mostly right\n  0 : extremely right\n  \n  RESPONSE GUIDELINE:\n  Think carefully about balancing left-right criteria for an accurate score. \n  Consider the speaker's arguments, values, and policy proposals. \n  If you are unsure about the score, \n  provide a justification for your uncertainty.\"\n  \n# use the ai_score function of quanteda.llm to summarize the texts\n\n# OPTION 1: using OpenAI's GPT-4o (not for free)\ncorpus &lt;- corpus %&gt;%\n  quanteda.tidy::mutate(llm_score_gpt = ai_score(text, chat_fn = chat_openai,\n                 api_args = list(temperature = 0, seed = 42), scale = scale))\nsave(corpus, file = \"corpus.RData\")\n# OPTION 2: using an open-source LLM with Ollama (for free)\ncorpus &lt;- corpus %&gt;%\n  quanteda.tidy::mutate(llm_score_llama = ai_score(text, chat_fn = chat_ollama, \n                                      model = \"llama3.2:1b\", scale = scale))\n\n# view the scores, added as docvars (meta data) to the quanteda corpus\nsummary(corpus)"
  },
  {
    "objectID": "blog/tutorial5/Tutorial/TutorialQuanteda.llm.html#validating-llms-responses",
    "href": "blog/tutorial5/Tutorial/TutorialQuanteda.llm.html#validating-llms-responses",
    "title": "How to use quanteda.llm for text analysis in R",
    "section": "Validating LLM‚Äôs responses",
    "text": "Validating LLM‚Äôs responses\n\nlibrary(tidyverse)\n\n# use the ai_validate function to manually check \n# the gpt responses regarding the scoring task\n# NOTE: this will start an easy-to-use Shiny app\n# validation input is temporarily saved in the working directory\ncorpus &lt;- corpus %&gt;%\n   quanteda.tidy::mutate(llm_val = ai_validate(text, llm_score_gpt))\n\n# the validation outcome is added as docvars (meta data) to the quanteda corpus\ndocvars(corpus)"
  },
  {
    "objectID": "blog/tutorial5/TutorialQuantedallm.html",
    "href": "blog/tutorial5/TutorialQuantedallm.html",
    "title": "How to use quanteda.llm for text analysis in R",
    "section": "",
    "text": "In this tutorial, we will work with the quanteda.llm package to perform text analysis tasks such as summarizing and scaling a large corpus of texts using either a closed (Option 1) or an open-source LLM (Option 2). Option 1 requires signing up for the OpenAI playground (not for free), while Option 2 uses the Ollama application to download an open-source LLM (which is free). The turorial is suitable for beginners and intermediate R users.\nIf you are new to R and RStudio, you can find a great introduction to R and RStudio on instats. For better visibility, I suggest you go to Tools -&gt; Global Options -&gt; Appearance -&gt; Editor theme and select Cobalt or Solarized Dark or any other theme that you like. In the tutorial, I will briefly explain core features of RStudio and how to handle Quarto files.\nQuarto enables you to weave together content and executable code into really nice research papers in various formats. To learn more about Quarto see https://quarto.org or check out my workshop on Quarto available on instats. When you click the Render button, a document will be generated that includes both content and (the output of) embedded code. This improves both readability and usability of your script. You can also easily add notes to this script while we are going through it. Go to the settings symbol beside the Render button to select that the preview of the document is shown in the Viewer pane."
  },
  {
    "objectID": "blog/tutorial5/TutorialQuantedallm.html#getting-text-summaries",
    "href": "blog/tutorial5/TutorialQuantedallm.html#getting-text-summaries",
    "title": "How to use quanteda.llm for text analysis in R",
    "section": "Getting text summaries",
    "text": "Getting text summaries\n\n# loading packages \n# (install them if you haven't already)\nlibrary(quanteda)\n#pak::pak(\"quanteda/quanteda.llm\")\n#pak::pak(\"quanteda/quanteda.tidy\")\nlibrary(quanteda.llm)\nlibrary(quanteda.tidy)\nlibrary(tidyverse)\nlibrary(ellmer)\n\n# load a corpus of US presidential inaugural speeches as a sample text corpus\n# (this corpus is included in the quanteda package)\ncorpus &lt;- quanteda::data_corpus_inaugural\n# subset the corpus to only include only the first 5 speeches \n# for demonstration purposes\ncorpus &lt;- corpus[1:5]\n# segment the corpus into smaller chunks as some LLMs have \n# a limit on the number of tokens they can process at once\n# you can indicate in the function the maximum number of tokens per chunk\ncorpus &lt;- quanteda::corpus_chunk(corpus, 1000)\n\n# use the ai_summarize function of quanteda.llm to summarize the texts\n\n# OPTION 1: using OpenAI's GPT-4o (not for free)\ncorpus &lt;- corpus %&gt;%\n  quanteda.tidy::mutate(llm_sum_gpt = ai_summarize(text, chat_fn = chat_openai,\n           api_args = list(temperature = 0, seed = 42), summary_length = \"20\"))\n# Note: The `temperature` parameter controls the randomness of \n# the model's output (0-1). The `seed` parameter ensures that the results \n# are reproducible (to some extent), see here for more details on the parameters: \n# https://ellmer.tidyverse.org/reference/index.html\n\n# OPTION 2: using an open-source LLM with Ollama (for free)\ncorpus &lt;- corpus %&gt;%\n  quanteda.tidy::mutate(llm_sum_llama = ai_summarize(text, chat_fn = chat_ollama, \n                                 model = \"llama3.2:1b\", summary_length = \"20\"))\n\n# view the summaries generated by both models \n# added as docvars (meta data) to the quanteda corpus\nsummary(corpus)"
  },
  {
    "objectID": "blog/tutorial5/TutorialQuantedallm.html#scoring-texts-based-on-a-scale",
    "href": "blog/tutorial5/TutorialQuantedallm.html#scoring-texts-based-on-a-scale",
    "title": "How to use quanteda.llm for text analysis in R",
    "section": "Scoring texts based on a scale",
    "text": "Scoring texts based on a scale\n\n# ai_score\nscale &lt;- \"TASK: You are a political scientist. \n  Score each speech on a left-right political values scale, \n  ranging from 0 to 6. \n  The political left is associated with values such as equality, \n  social justice, and social change. \n  The political right is associated with values \n  such as individualism, free markets, and national security. \n  Provide a score for each speech and a short justification \n  for your score in a separate paragraph.\n  \n  SCORING METRIC:\n  6 : extremely left\n  5 : mostly left\n  4 : slightly left\n  3 : neither right or left\n  2 : slightly right\n  1 : mostly right\n  0 : extremely right\n  \n  RESPONSE GUIDELINE:\n  Think carefully about balancing left-right criteria for an accurate score. \n  Consider the speaker's arguments, values, and policy proposals. \n  If you are unsure about the score, \n  provide a justification for your uncertainty.\"\n  \n# use the ai_score function of quanteda.llm to summarize the texts\n\n# OPTION 1: using OpenAI's GPT-4o (not for free)\ncorpus &lt;- corpus %&gt;%\n  quanteda.tidy::mutate(llm_score_gpt = ai_score(text, chat_fn = chat_openai,\n                 api_args = list(temperature = 0, seed = 42), scale = scale))\nsave(corpus, file = \"corpus.RData\")\n# OPTION 2: using an open-source LLM with Ollama (for free)\ncorpus &lt;- corpus %&gt;%\n  quanteda.tidy::mutate(llm_score_llama = ai_score(text, chat_fn = chat_ollama, \n                                      model = \"llama3.2:1b\", scale = scale))\n\n# view the scores, added as docvars (meta data) to the quanteda corpus\nsummary(corpus)"
  },
  {
    "objectID": "blog/tutorial5/TutorialQuantedallm.html#validating-llms-responses",
    "href": "blog/tutorial5/TutorialQuantedallm.html#validating-llms-responses",
    "title": "How to use quanteda.llm for text analysis in R",
    "section": "Validating LLM‚Äôs responses",
    "text": "Validating LLM‚Äôs responses\n\nlibrary(tidyverse)\n\n# use the ai_validate function to manually check \n# the gpt responses regarding the scoring task\n# NOTE: this will start an easy-to-use Shiny app\n# validation input is temporarily saved in the working directory\ncorpus &lt;- corpus %&gt;%\n   quanteda.tidy::mutate(llm_val = ai_validate(text, llm_score_gpt))\n\n# the validation outcome is added as docvars (meta data) to the quanteda corpus\ndocvars(corpus)"
  }
]